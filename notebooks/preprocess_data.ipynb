{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process Data: Specific DSAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pre-Process Data\n",
    "\n",
    "Convert the raw data counts into sc-RNAseq compatible data format.\n",
    "\n",
    "Each dataset may have many different samples. We may decide to split the data taking this into consideration or not. \n",
    "\n",
    "We will here contemplate 3 types of train/test/validation splits:\n",
    "    1. 0 Dataset Leakage: No overlap between datasets\n",
    "    2. Train-Test Dataset Leakage: Overlap between train and test datasets\n",
    "    3. Train-Test-Validation Dataset Leakage: Overlap between train, test, and validation datasets\n",
    "\n",
    "\n",
    "Structure:\n",
    "    1. Imports, Variables, Functions\n",
    "    2. Load Data\n",
    "    3. Convert to `adata` object\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 1. Imports, Variables, Functions\n",
    "# imports\n",
    "import numpy as np, os, sys, pandas as pd, scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "# variables\n",
    "example_data_path = (\n",
    "    \"/aloy/home/ddalton/projects/disease_signatures/data/DiSignAtlas/tmp/DSA00015.csv\"\n",
    ")\n",
    "\n",
    "# functions\n",
    "\n",
    "\n",
    "# 2. Load Data\n",
    "df = pd.read_csv(example_data_path, index_col=0)\n",
    "\n",
    "# 3. Convert to `adata` object\n",
    "\n",
    "\n",
    "# Extract cell identifiers and gene expression data\n",
    "cell_ids = df.iloc[:, 0]\n",
    "gene_expression_data = df.iloc[:, 1:].values\n",
    "gene_names = df.columns[1:]\n",
    "\n",
    "\n",
    "# Create an AnnData object\n",
    "adata = ad.AnnData(X=gene_expression_data)\n",
    "\n",
    "\n",
    "# Add cell and gene metadata\n",
    "adata.obs[\"cell_ids\"] = cell_ids.values\n",
    "adata.var[\"gene_symbols\"] = gene_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data: Specific Diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 16:13:51,285 - Nº of DSAIDs of interest: 286\n",
      "100%|██████████| 286/286 [03:13<00:00,  1.48it/s]\n",
      "2024-08-14 16:17:04,621 - Loaded dataframe with shape: (10963, 19691)\n",
      "2024-08-14 16:17:05,040 - Filtered dataframe with shape: (10791, 19691)\n",
      "2024-08-14 16:17:05,380 - Filtered out Unkowns from dataframe with shape: (10583, 19691)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Pre-Process Data\n",
    "\n",
    "Convert the raw data counts into sc-RNAseq compatible data format.\n",
    "\n",
    "Structure:\n",
    "    1. Imports, Variables, Functions\n",
    "    2. Load Data\n",
    "    3. Convert to `adata` object\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 1. Imports, Variables, Functions\n",
    "# imports\n",
    "import numpy as np, os, sys, pandas as pd, scanpy as sc\n",
    "import anndata as ad\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# import random\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# variables\n",
    "diseases_of_interest_set = {\"Influenza\", \"Colorectal Carcinoma\", \"Breast Cancer\"}\n",
    "diseases_of_interest_set = {\n",
    "    \"Crohn's Disease\",\n",
    "    \"Ulcerative Colitis\",\n",
    "    \"Lung Cancer\",\n",
    "    \"Lung Adenocarcinoma\",\n",
    "    \"Breast Cancer\",\n",
    "    \"Psoriasis\",\n",
    "}\n",
    "\n",
    "\n",
    "example_data_path = (\n",
    "    \"/aloy/home/ddalton/projects/disease_signatures/data/DiSignAtlas/tmp/DSA00123.csv\"\n",
    ")\n",
    "\n",
    "df_info_path = os.path.join(\n",
    "    \"/aloy\",\n",
    "    \"home\",\n",
    "    \"ddalton\",\n",
    "    \"projects\",\n",
    "    \"disease_signatures\",\n",
    "    \"data\",\n",
    "    \"DiSignAtlas\",\n",
    "    \"Disease_information_Datasets_extended.csv\",\n",
    ")\n",
    "\n",
    "\n",
    "large_df_path = \"/aloy/home/ddalton/projects/disease_signatures/data/DiSignAtlas/DiSignAtlas.exp_prof_merged.csv\"\n",
    "\n",
    "\n",
    "# functions\n",
    "def get_exp_prof(dsaids_interest):\n",
    "    \"\"\"Get Expression Profiles\"\"\"\n",
    "\n",
    "    # variables\n",
    "    file_dir = \"/aloy/home/ddalton/projects/disease_signatures/data/DiSignAtlas/tmp/\"\n",
    "    first = True\n",
    "    for dsaid in tqdm(dsaids_interest):\n",
    "        __df = pd.read_csv(os.path.join(file_dir, f\"{dsaid}.csv\"))\n",
    "        if first:\n",
    "            df_global = __df\n",
    "            first = False\n",
    "        else:\n",
    "            df_global = pd.concat([df_global, __df], axis=0)\n",
    "    return df_global\n",
    "\n",
    "\n",
    "def get_dataset_info(ids, df_info):\n",
    "    \"\"\"Get Disease Information\"\"\"\n",
    "    dsaid_2_accession = dict(zip(df_info[\"dsaid\"], df_info[\"accession\"]))\n",
    "\n",
    "    dataset_accessions = [dsaid_2_accession[id.split(\";\")[0]] for id in ids]\n",
    "\n",
    "    accession_2_id = {k: v for v, k in enumerate(set(dataset_accessions))}\n",
    "    dataset_ids = [accession_2_id[accession] for accession in dataset_accessions]\n",
    "\n",
    "    return dataset_accessions, dataset_ids\n",
    "\n",
    "\n",
    "def get_disease_info(ids, df_info):\n",
    "    \"\"\"Get Disease Information\"\"\"\n",
    "    dsaid_2_disease = dict(zip(df_info[\"dsaid\"], df_info[\"disease\"]))\n",
    "    disease_types = list()\n",
    "    for id in ids:\n",
    "        if id.split(\";\")[2] == \"Control\":\n",
    "            disease_types.append(\"Control\")\n",
    "        elif id.split(\";\")[2] == \"Case\":\n",
    "            disease_types.append(dsaid_2_disease[id.split(\";\")[0]])\n",
    "        else:\n",
    "            print(f\"Error with ID: {id}\")\n",
    "\n",
    "    map_2_id = {k: v for v, k in enumerate(set(disease_types))}\n",
    "\n",
    "    disease_ids = [map_2_id[x] for x in disease_types]\n",
    "\n",
    "    return disease_types, disease_ids\n",
    "\n",
    "\n",
    "# 2. Load Data\n",
    "# df = pd.read_csv(example_data_path)\n",
    "\n",
    "df_info = pd.read_csv(df_info_path)\n",
    "\n",
    "\n",
    "# Query data to retrieve dsaids of interest\n",
    "library_strategies_of_interest_set = {\"RNA-seq\", \"Microarray\"}\n",
    "QUERY = \"disease in @diseases_of_interest_set & library_strategy in @library_strategies_of_interest_set & organism == 'Homo sapiens'\"\n",
    "dsaids_interest = df_info.query(QUERY)[\"dsaid\"].to_list()\n",
    "logging.info(f\"Nº of DSAIDs of interest: {len(dsaids_interest)}\")\n",
    "\n",
    "# skip_rows_idxs = get_skip_rows(dsaids_interest)\n",
    "\n",
    "df = get_exp_prof(dsaids_interest)\n",
    "\n",
    "# 3. Convert to `adata` object\n",
    "# load dataframe\n",
    "# df = pd.read_csv(large_df_path, skiprows=skip_rows_idxs, index_col=0)\n",
    "logging.info(f\"Loaded dataframe with shape: {df.shape}\")\n",
    "\n",
    "# drop non significant rows\n",
    "# Calculate the number of NaNs in each row\n",
    "nan_counts = df.isna().sum(axis=1)\n",
    "\n",
    "# Filter the DataFrame to keep only rows with NaNs less than or equal to 18,000\n",
    "df = df[nan_counts <= 18000]\n",
    "logging.info(f\"Filtered dataframe with shape: {df.shape}\")\n",
    "\n",
    "# Filter out Unknown samples\n",
    "mask = [False if id.split(\";\")[2] == \"Unknown\" else True for id in df.iloc[:, 0].values]\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "logging.info(f\"Filtered out Unkowns from dataframe with shape: {df.shape}\")\n",
    "\n",
    "\n",
    "# 3. Convert to `adata` object\n",
    "# Extract cell identifiers and gene expression data\n",
    "ids = df.iloc[:, 0]\n",
    "gene_expression_data = df.iloc[:, 1:].values\n",
    "gene_names = df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AnnData object\n",
    "adata = ad.AnnData(X=gene_expression_data)\n",
    "\n",
    "\n",
    "# Add cell and gene metadata\n",
    "adata.obs[\"ids\"] = ids.values\n",
    "adata.var[\"gene_symbols\"] = gene_names\n",
    "adata.var[\"index\"] = gene_names\n",
    "adata.var[\"gene_name\"] = gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 16:33:21,681 - Counts of each disease type: Counter({'Control': 4041, 'Ulcerative Colitis': 1776, 'Breast Cancer': 1740, \"Crohn's Disease\": 1469, 'Psoriasis': 960, 'Lung Adenocarcinoma': 335, 'Lung Cancer': 262})\n"
     ]
    }
   ],
   "source": [
    "# generate celltype and celltype_id columns in adata.obs\n",
    "disease_types, disease_ids = get_disease_info(ids.values, df_info=df_info)\n",
    "adata.obs[\"celltype\"] = disease_types\n",
    "adata.obs[\"celltype_id\"] = disease_ids\n",
    "\n",
    "logging.info(f\"Counts of each disease type: {Counter(disease_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 16:33:23,120 - Counts of each dataset id: Counter({'GSE206285': 566, 'GSE13355': 468, 'GSE66407': 452, 'GSE54002': 431, 'GSE112366': 410, 'GSE119600': 278, 'GSE87650': 267, 'GSE48634': 235, 'GSE75214': 224, 'GSE179285': 201, 'GSE5364': 194, 'GSE40791': 192, 'GSE97012': 191, 'GSE123086': 188, 'GSE4115': 185, 'GSE92415': 181, 'GSE20881': 168, 'GSE3365': 165, 'GSE14905': 163, 'GSE45827': 162, 'GSE136757': 159, 'GSE20189': 155, 'GSE13367': 149, 'GSE27562': 146, 'GSE87473': 144, 'GSE24124': 135, 'GSE126124': 123, 'GSE24287': 120, 'GSE16443': 119, 'GSE42568': 119, 'GSE29044': 107, 'GSE37751': 106, 'GSE83582': 106, 'GSE10072': 105, 'GSE60083': 98, 'GSE94648': 96, 'GSE192867': 90, 'GSE18842': 89, 'GSE7670': 84, 'GSE6710': 77, 'GSE55201': 72, 'GSE38713': 69, 'GSE43458': 68, 'GSE95095': 68, 'GSE29431': 64, 'GSE32407': 60, 'GSE61304': 58, 'GSE42826': 58, 'GSE102133': 56, 'GSE10810': 56, 'GSE71730': 56, 'GSE75343': 54, 'GSE105074': 52, 'GSE53306': 52, 'GSE83448': 51, 'GSE110933': 48, 'GSE36295': 48, 'GSE27262': 48, 'GSE31547': 48, 'GSE53552': 47, 'GSE41662': 46, 'GSE3744': 45, 'GSE139038': 45, 'GSE6731': 44, 'GSE42830': 44, 'GSE36807': 42, 'GSE20437': 40, 'GSE32488': 37, 'GSE123087': 36, 'GSE75916': 36, 'GSE9452': 32, 'GSE9686': 32, 'GSE206311': 32, 'GSE144521': 32, 'GSE10191': 31, 'GSE109248': 31, 'GSE52471': 31, 'GSE40263': 30, 'GSE69762': 30, 'GSE80759': 30, 'GSE41663': 30, 'GSE54495': 30, 'GSE9574': 29, 'GSE48958': 29, 'GSE65114': 28, 'GSE14580': 28, 'GSE34248': 28, 'GSE52746': 27, 'GSE67853': 27, 'GSE57383': 27, 'GSE57405': 27, 'GSE37283': 25, 'GSE110186': 24, 'GSE53431': 24, 'GSE47598': 24, 'E-MTAB-5385': 21, 'GSE47908': 21, 'GSE50627': 21, 'GSE22619': 20, 'GSE178753': 20, 'GSE32175': 20, 'GSE20266': 20, 'GSE11545': 20, 'GSE185764': 19, 'GSE10799': 19, 'GSE141804': 19, 'GSE25487': 19, 'GSE71053': 18, 'GSE66387': 18, 'GSE70469': 18, 'GSE71363': 18, 'GSE37911': 18, 'GSE75890': 17, 'GSE1987': 16, 'GSE185645': 16, 'GSE89047': 16, 'GSE36765': 14, 'GSE10714': 13, 'GSE118370': 12, 'GSE26910': 12, 'GSE157737': 12, 'GSE23361': 12, 'GSE42632': 12, 'GSE85716': 12, 'GSE160932': 12, 'GSE26952': 11, 'GSE40033': 11, 'GSE68570': 11, 'GSE2737': 10, 'GSE7700': 10, 'GSE120464': 9, 'GSE72780': 9, 'GSE166388': 8, 'GSE63571': 8, 'GSE19295': 8, 'GSE144338': 8, 'GSE26990': 8, 'GSE50790': 8, 'GSE65517': 7, 'GSE106937': 6, 'GSE106087': 6, 'GSE134025': 6, 'GSE128610': 6, 'GSE31138': 6, 'GSE73613': 4, 'GSE26305': 4})\n"
     ]
    }
   ],
   "source": [
    "# generate dataset ids column in adata.obs\n",
    "dataset_ids, batch_ids = get_dataset_info(ids.values, df_info=df_info)\n",
    "\n",
    "adata.obs[\"dataset_id\"] = dataset_ids\n",
    "adata.obs[\"batch_id\"] = batch_ids\n",
    "\n",
    "logging.info(f\"Counts of each dataset id: {Counter(dataset_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10583, 5)\n",
      "(164, 2)\n"
     ]
    }
   ],
   "source": [
    "# copy\n",
    "df_val_split = adata.obs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>celltype</th>\n",
       "      <th>dataset_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lung Adenocarcinoma</td>\n",
       "      <td>GSE7670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>GSE9574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Psoriasis</td>\n",
       "      <td>GSE6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Psoriasis</td>\n",
       "      <td>GSE136757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Psoriasis</td>\n",
       "      <td>GSE185764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10240</th>\n",
       "      <td>Psoriasis</td>\n",
       "      <td>GSE160932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10258</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>GSE45827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10415</th>\n",
       "      <td>Lung Adenocarcinoma</td>\n",
       "      <td>GSE10072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10456</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>GSE25487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10554</th>\n",
       "      <td>Lung Adenocarcinoma</td>\n",
       "      <td>GSE31547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  celltype dataset_id\n",
       "29     Lung Adenocarcinoma    GSE7670\n",
       "99           Breast Cancer    GSE9574\n",
       "126              Psoriasis    GSE6710\n",
       "167              Psoriasis  GSE136757\n",
       "301              Psoriasis  GSE185764\n",
       "...                    ...        ...\n",
       "10240            Psoriasis  GSE160932\n",
       "10258        Breast Cancer   GSE45827\n",
       "10415  Lung Adenocarcinoma   GSE10072\n",
       "10456        Breast Cancer   GSE25487\n",
       "10554  Lung Adenocarcinoma   GSE31547\n",
       "\n",
       "[164 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 18:34:01,993 - Data leakage: 5\n",
      "2024-08-14 18:34:01,993 - Train: 114, Test: 50\n",
      "2024-08-14 18:34:01,994 - Number of diseases in train: 6, Number of diseases in test: 6\n",
      "2024-08-14 18:34:01,994 - Train disease-dataset counts: Counter({'Breast Cancer': 29, 'Psoriasis': 23, 'Ulcerative Colitis': 21, \"Crohn's Disease\": 19, 'Lung Adenocarcinoma': 9, 'Lung Cancer': 8})\n",
      "2024-08-14 18:34:01,995 - Test disease-dataset counts: Counter({'Ulcerative Colitis': 14, 'Psoriasis': 12, 'Breast Cancer': 12, \"Crohn's Disease\": 11, 'Lung Adenocarcinoma': 5, 'Lung Cancer': 1})\n",
      "2024-08-14 18:34:01,995 - Original train/test ratio: 0.3\n",
      "Dataset train/test ratio: 0.34\n",
      "Sample Ratio: 0.30\n"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "\n",
    "\n",
    "def test_split(\n",
    "    df_obs: pd.DataFrame, ratio: float = 0.15, random_state: int = 42\n",
    ") -> List[bool]:\n",
    "    \"\"\"\n",
    "    Splits the dataset into a validation set based on the specified ratio.\n",
    "\n",
    "    Args:\n",
    "        df_obs (pd.DataFrame): DataFrame containing the observational data.\n",
    "        ratio (float): The ratio of the dataset to be used for validation.\n",
    "\n",
    "    Returns:\n",
    "        mask (List[bool]): A boolean mask indicating which samples belong to the validation set.\n",
    "    \"\"\"\n",
    "\n",
    "    df_val_split = df_obs.copy()\n",
    "\n",
    "    # Columns of interest\n",
    "    interest_columns = [\"celltype\", \"dataset_id\"]\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    columns_to_remove = list(set(df_val_split.columns) - set(interest_columns))\n",
    "    df_val_split.drop(columns=columns_to_remove, inplace=True)\n",
    "\n",
    "    # Filter out control samples and remove duplicates\n",
    "    df_val_split = df_val_split[df_val_split[\"celltype\"] != \"Control\"].drop_duplicates()\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X = df_val_split[\"dataset_id\"].values\n",
    "    y = df_val_split[\"celltype\"].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=ratio, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Check for dataset leakage\n",
    "    dataset_leakage = set(X_train) & set(X_test)\n",
    "    logging.info(f\"Data leakage: {len(dataset_leakage)}\")\n",
    "\n",
    "    logging.info(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "    # Remove leakage from training set\n",
    "    X_train = list(set(X_train) - dataset_leakage)\n",
    "\n",
    "    dataset_leakage = set(X_train) & set(X_test)\n",
    "    assert len(dataset_leakage) == 0, \"Dataset leakage still present\"\n",
    "\n",
    "    # Check for sufficient data in each split\n",
    "    train_diseases = df_val_split[df_val_split[\"dataset_id\"].isin(X_train)][\"celltype\"]\n",
    "    test_diseases = df_val_split[df_val_split[\"dataset_id\"].isin(X_test)][\"celltype\"]\n",
    "\n",
    "    assert len(set(train_diseases)) == len(\n",
    "        set(test_diseases)\n",
    "    ), \"Train and test diseases differ\"\n",
    "\n",
    "    logging.info(\n",
    "        f\"Number of diseases in train: {len(set(train_diseases))}, \"\n",
    "        f\"Number of diseases in test: {len(set(test_diseases))}\"\n",
    "    )\n",
    "    logging.info(f\"Train disease-dataset counts: {Counter(train_diseases)}\")\n",
    "    logging.info(f\"Test disease-dataset counts: {Counter(test_diseases)}\")\n",
    "\n",
    "    # Generate the validation set mask\n",
    "    mask = df_obs[\"dataset_id\"].isin(X_test)\n",
    "\n",
    "    logging.info(\n",
    "        f\"Original train/test ratio: {ratio}\\n\"\n",
    "        f\"Dataset train/test ratio: {len(X_test) / (len(X_train)+len(X_test)):.2f}\\n\"\n",
    "        f\"Sample Ratio: {mask.sum() / len(mask):.2f}\"\n",
    "    )\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "mask_validation = test_split(df_obs=adata.obs, ratio=0.3, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 14:40:37,048 - Nº of single label indexes: 1\n",
      "2024-08-14 14:40:37,057 - Nº of train samples: 8466\n",
      "2024-08-14 14:40:37,058 - Nº of test samples: 2117\n"
     ]
    }
   ],
   "source": [
    "# We combine both the disease type with the dataset as to\n",
    "# shuffle even more the data - minimize bias in train/test split\n",
    "labels = np.array([a + b for a, b in zip(disease_types, dataset_ids)])\n",
    "\n",
    "# Generate indices for the data points\n",
    "indices = np.arange(len(labels))\n",
    "\n",
    "\"\"\"train_test_split cannot handle single label indexes\n",
    "\n",
    "Because of this we will manually deal with these cases!\n",
    "\n",
    "\"\"\"\n",
    "indices_single_label = [i for i, x in enumerate(labels) if list(labels).count(x) == 1]\n",
    "labels_single_label = labels[indices_single_label]\n",
    "\n",
    "logging.info(f\"Nº of single label indexes: {len(indices_single_label)}\")\n",
    "\n",
    "\n",
    "remaining_indices = [i for i in indices if i not in indices_single_label]\n",
    "remaining_labels = labels[remaining_indices]\n",
    "\n",
    "# Perform stratified split on the remaining indices\n",
    "train_indices, test_indices = train_test_split(\n",
    "    remaining_indices, test_size=0.2, stratify=remaining_labels, random_state=42\n",
    ")\n",
    "\n",
    "for idx in indices_single_label:\n",
    "\n",
    "    if random.random() < 0.2:\n",
    "        test_indices.append(idx)\n",
    "    else:\n",
    "        train_indices.append(idx)\n",
    "\n",
    "\n",
    "test_indices.sort()\n",
    "train_indices.sort()\n",
    "\n",
    "batch_ids = np.zeros(len(labels))\n",
    "batch_ids[test_indices] = 1\n",
    "\n",
    "\n",
    "logging.info(f\"Nº of train samples: {np.sum(~batch_ids.astype(bool))}\")\n",
    "logging.info(f\"Nº of test samples: {np.sum(batch_ids.astype(bool))}\")\n",
    "\n",
    "\n",
    "adata.obs[\"train_test\"] = batch_ids\n",
    "adata.obs[\"str_batch\"] = batch_ids.astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'str_batch' as categorical\n"
     ]
    }
   ],
   "source": [
    "# save adata object\n",
    "# adata.write(\"../data/test_1/test_1.h5ad\")\n",
    "adata.write(\"../data/test_1/test_2.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>celltype</th>\n",
       "      <th>celltype_id</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>train_test</th>\n",
       "      <th>batch_str</th>\n",
       "      <th>str_batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DSA00057;GSM2062351;Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "      <td>GSE77953</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSA00057;GSM2062352;Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "      <td>GSE77953</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSA00057;GSM2062353;Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "      <td>GSE77953</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSA00057;GSM2062354;Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "      <td>GSE77953</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSA00057;GSM2062355;Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "      <td>GSE77953</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5085</th>\n",
       "      <td>DSA10295;GSM1012438;Case</td>\n",
       "      <td>Colorectal Carcinoma</td>\n",
       "      <td>3</td>\n",
       "      <td>GSE41258</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5086</th>\n",
       "      <td>DSA10295;GSM1012444;Case</td>\n",
       "      <td>Colorectal Carcinoma</td>\n",
       "      <td>3</td>\n",
       "      <td>GSE41258</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>DSA10295;GSM1012448;Case</td>\n",
       "      <td>Colorectal Carcinoma</td>\n",
       "      <td>3</td>\n",
       "      <td>GSE41258</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5088</th>\n",
       "      <td>DSA10295;GSM1012449;Case</td>\n",
       "      <td>Colorectal Carcinoma</td>\n",
       "      <td>3</td>\n",
       "      <td>GSE41258</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>DSA10295;GSM1012450;Case</td>\n",
       "      <td>Colorectal Carcinoma</td>\n",
       "      <td>3</td>\n",
       "      <td>GSE41258</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5090 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ids              celltype  celltype_id  \\\n",
       "0     DSA00057;GSM2062351;Control               Control            0   \n",
       "1     DSA00057;GSM2062352;Control               Control            0   \n",
       "2     DSA00057;GSM2062353;Control               Control            0   \n",
       "3     DSA00057;GSM2062354;Control               Control            0   \n",
       "4     DSA00057;GSM2062355;Control               Control            0   \n",
       "...                           ...                   ...          ...   \n",
       "5085     DSA10295;GSM1012438;Case  Colorectal Carcinoma            3   \n",
       "5086     DSA10295;GSM1012444;Case  Colorectal Carcinoma            3   \n",
       "5087     DSA10295;GSM1012448;Case  Colorectal Carcinoma            3   \n",
       "5088     DSA10295;GSM1012449;Case  Colorectal Carcinoma            3   \n",
       "5089     DSA10295;GSM1012450;Case  Colorectal Carcinoma            3   \n",
       "\n",
       "     dataset_id  batch_id  train_test  batch_str  str_batch  \n",
       "0      GSE77953        23         0.0        0.0        0.0  \n",
       "1      GSE77953        23         1.0        1.0        1.0  \n",
       "2      GSE77953        23         0.0        0.0        0.0  \n",
       "3      GSE77953        23         0.0        0.0        0.0  \n",
       "4      GSE77953        23         1.0        1.0        1.0  \n",
       "...         ...       ...         ...        ...        ...  \n",
       "5085   GSE41258        16         0.0        0.0        0.0  \n",
       "5086   GSE41258        16         1.0        1.0        1.0  \n",
       "5087   GSE41258        16         0.0        0.0        0.0  \n",
       "5088   GSE41258        16         0.0        0.0        0.0  \n",
       "5089   GSE41258        16         0.0        0.0        0.0  \n",
       "\n",
       "[5090 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will create an \"artifical\" cell type which\n",
    "# will represent the diseases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
