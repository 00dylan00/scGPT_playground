17:11:35-scGPT-INFO-<module>: match 2996/3000 genes in vocabulary of size 60697.
17:11:35-scGPT-INFO-<module>: Resume model from ../../scGPT/save/scGPT_human/best_model.pt, the model args will override the config ../../scGPT/save/scGPT_human/args.json.
17:11:35-scGPT-INFO-__call__: Normalizing total counts ...
17:11:35-scGPT-INFO-__call__: Log1p transforming ...
17:11:35-scGPT-WARNING-__call__: The input data seems to be already log1p transformed. Set `log1p=False` to avoid double log1p transform.
17:11:35-scGPT-INFO-__call__: Binning data ...
17:11:38-scGPT-INFO-__call__: Normalizing total counts ...
17:11:38-scGPT-INFO-__call__: Log1p transforming ...
17:11:38-scGPT-WARNING-__call__: The input data seems to be already log1p transformed. Set `log1p=False` to avoid double log1p transform.
17:11:38-scGPT-INFO-__call__: Binning data ...
17:11:39-scGPT-INFO-<module>: train set number of samples: 7619, 
	 feature length: 2997
17:11:39-scGPT-INFO-<module>: valid set number of samples: 847, 
	 feature length: 2997
17:11:39-scGPT-INFO-<module>: Total Pre freeze Params 51335176
17:11:39-scGPT-INFO-<module>: Total Post freeze Params 51335176
17:12:28-scGPT-INFO-train: | epoch   1 | 100/239 batches | lr 0.0001 | ms/batch 477.10 | loss  1.23 | cls  1.23 | err  0.46 | 
17:13:14-scGPT-INFO-train: | epoch   1 | 200/239 batches | lr 0.0001 | ms/batch 461.13 | loss  0.99 | cls  0.99 | err  0.38 | 
17:13:35-scGPT-INFO-<module>: -----------------------------------------------------------------------------------------
17:13:35-scGPT-INFO-<module>: | end of epoch   1 | time: 115.98s | valid loss/mse 0.9711 | err 0.3790
17:13:35-scGPT-INFO-<module>: -----------------------------------------------------------------------------------------
17:13:35-scGPT-INFO-<module>: Best model with score 0.9711
